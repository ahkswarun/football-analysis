{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce910f3",
   "metadata": {},
   "source": [
    "TEST 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "cap = cv2.VideoCapture('15sec_input_720p.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference\n",
    "    results = model(frame)\n",
    "\n",
    "    # Visualize results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Show the annotated frame\n",
    "    cv2.imshow('Player Detection', annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2522804",
   "metadata": {},
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa535a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Load your YOLOv11 model\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Initialize DeepSORT Tracker\n",
    "tracker = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0)\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture('15sec_input_720p.mp4')\n",
    "\n",
    "# Get video properties for saving\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "out = cv2.VideoWriter('output_with_tracking.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Calculate delay for real-time-like playback\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run detection\n",
    "    results = model(frame)\n",
    "\n",
    "    detections = []\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        confs = r.boxes.conf.cpu().numpy()\n",
    "        clss = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "        for box, conf, cls in zip(boxes, confs, clss):\n",
    "            if int(cls) == 0 and conf > 0.5:  # Assuming class 0 is player\n",
    "                x1, y1, x2, y2 = box\n",
    "                detections.append(([x1, y1, x2, y2], conf, 'player'))\n",
    "\n",
    "    # Update tracker\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    # Draw results\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        x1, y1, x2, y2 = map(int, ltrb)\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Player {track_id}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Save the annotated frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # Show the annotated frame\n",
    "    cv2.imshow('Player Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed0d7f",
   "metadata": {},
   "source": [
    "TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "# Centroid Tracker Class\n",
    "class CentroidTracker:\n",
    "    def __init__(self, max_disappeared=40):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = {}  # ID -> centroid\n",
    "        self.disappeared = {}\n",
    "        self.max_disappeared = max_disappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.max_disappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        for (i, (x1, y1, x2, y2)) in enumerate(rects):\n",
    "            cX = int((x1 + x2) / 2.0)\n",
    "            cY = int((y1 + y2) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                self.objects[objectIDs[row]] = inputCentroids[col]\n",
    "                self.disappeared[objectIDs[row]] = 0\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            unusedRows = set(range(0, D.shape[0])) - usedRows\n",
    "            unusedCols = set(range(0, D.shape[1])) - usedCols\n",
    "\n",
    "            for row in unusedRows:\n",
    "                objectID = objectIDs[row]\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.max_disappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            for col in unusedCols:\n",
    "                self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "    \n",
    "    # Load YOLOv11 model\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Initialize tracker\n",
    "ct = CentroidTracker()\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture('15sec_input_720p.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference\n",
    "    results = model(frame)\n",
    "\n",
    "    rects = []\n",
    "    player_data = []\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        confs = r.boxes.conf.cpu().numpy()\n",
    "        clss = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "        for box, conf, cls in zip(boxes, confs, clss):\n",
    "            print(f\"Detected class: {int(cls)}, confidence: {conf}\")\n",
    "\n",
    "            if int(cls) == 1 and conf > 0.5:  # Replace 1 with correct player class if needed\n",
    "                x1, y1, x2, y2 = box\n",
    "                cX = int((x1 + x2) / 2.0)\n",
    "                cY = int((y1 + y2) / 2.0)\n",
    "                player_data.append(((cX, cY), (x1, y1, x2, y2)))\n",
    "\n",
    "    centroids = [d[0] for d in player_data]\n",
    "    objects = ct.update(centroids) \n",
    "\n",
    "    # Draw tracked objects with consistent IDs\n",
    "    for (objectID, centroid) in objects.items():\n",
    "    # Find matching bounding box\n",
    "        for (c, (x1, y1, x2, y2)) in player_data:\n",
    "            if np.linalg.norm(np.array(centroid) - np.array(c)) < 30:\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Player {objectID}', (int(x1), int(y1) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Player Detection with Consistent IDs', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd41186",
   "metadata": {},
   "source": [
    "TEST 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the fine-tuned YOLOv8 model\n",
    "model = YOLO('best.pt') \n",
    "\n",
    "# Open the video file\n",
    "video_path = '15sec_input_720p.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video {video_path}\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # --- KEY CHANGE: Use model.track() instead of model() ---\n",
    "    # 'persist=True' tells the tracker to remember identities between frames\n",
    "    results = model.track(frame, persist=True)\n",
    "\n",
    "    # Check if any tracks were detected\n",
    "    if results[0].boxes.id is not None:\n",
    "        # Get the bounding boxes, track IDs, and confidence scores\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "        confidences = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "        # Loop through each detected player\n",
    "        for box, track_id, conf in zip(boxes, track_ids, confidences):\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "\n",
    "            # Create the label text with Player ID and confidence\n",
    "            label = f\"Player ID: {track_id}\"\n",
    "            \n",
    "            # Position the label text above the bounding box\n",
    "            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            cv2.rectangle(frame, (box[0], box[1] - label_size[1] - 5), (box[0] + label_size[0], box[1]), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, label, (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    # Show the annotated frame\n",
    "    cv2.imshow('Player Tracking', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc141a3",
   "metadata": {},
   "source": [
    "TEST 4 PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4999b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- COLOR/TEAM DEFINITIONS ---\n",
    "# Define HSV color ranges for Red and Sky Blue\n",
    "\n",
    "# Red wraps around the 0-180 hue scale\n",
    "LOWER_RED_1 = np.array([0, 120, 70])\n",
    "UPPER_RED_1 = np.array([10, 255, 255])\n",
    "LOWER_RED_2 = np.array([170, 120, 70])\n",
    "UPPER_RED_2 = np.array([180, 255, 255])\n",
    "\n",
    "# UPDATED: HSV range for Sky Blue (more towards cyan, allows for lower saturation)\n",
    "LOWER_SKY_BLUE = np.array([90, 70, 50])\n",
    "UPPER_SKY_BLUE = np.array([120, 255, 255])\n",
    "\n",
    "# BGR colors for drawing boxes\n",
    "RED_COLOR_BGR = (0, 0, 255)\n",
    "# UPDATED: A lighter BGR color to represent Sky Blue\n",
    "SKY_BLUE_COLOR_BGR = (235, 206, 135) \n",
    "GREEN_COLOR_BGR = (0, 255, 0) # For undetermined\n",
    "\n",
    "def get_player_team(player_roi):\n",
    "    \"\"\"\n",
    "    Analyzes a player's Region of Interest (ROI) to determine their team color.\n",
    "    \n",
    "    Args:\n",
    "        player_roi (np.array): The cropped image of the player.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the team name (str) and the BGR color for the bounding box.\n",
    "    \"\"\"\n",
    "    if player_roi.size == 0:\n",
    "        return \"Undetermined\", GREEN_COLOR_BGR\n",
    "\n",
    "    # Convert ROI to HSV color space\n",
    "    hsv_roi = cv2.cvtColor(player_roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create masks for red and sky blue colors\n",
    "    red_mask1 = cv2.inRange(hsv_roi, LOWER_RED_1, UPPER_RED_1)\n",
    "    red_mask2 = cv2.inRange(hsv_roi, LOWER_RED_2, UPPER_RED_2)\n",
    "    red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "    \n",
    "    # UPDATED: Use the new sky blue mask\n",
    "    sky_blue_mask = cv2.inRange(hsv_roi, LOWER_SKY_BLUE, UPPER_SKY_BLUE)\n",
    "\n",
    "    # Count the number of red and sky blue pixels\n",
    "    red_pixel_count = cv2.countNonZero(red_mask)\n",
    "    sky_blue_pixel_count = cv2.countNonZero(sky_blue_mask)\n",
    "\n",
    "    # Determine team based on which color is more dominant\n",
    "    if red_pixel_count > sky_blue_pixel_count and red_pixel_count > 10: # Min pixel threshold\n",
    "        return \"Red Team\", RED_COLOR_BGR\n",
    "    elif sky_blue_pixel_count > red_pixel_count and sky_blue_pixel_count > 10:\n",
    "        # UPDATED: Return \"Sky Blue Team\" and the new color\n",
    "        return \"Sky Blue Team\", SKY_BLUE_COLOR_BGR\n",
    "    else:\n",
    "        return \"Undetermined\", GREEN_COLOR_BGR\n",
    "\n",
    "# --- MAIN SCRIPT ---\n",
    "\n",
    "# Load the fine-tuned YOLOv8 model\n",
    "model = YOLO('best.pt') \n",
    "\n",
    "# Open the video file\n",
    "video_path = '15sec_input_720p.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video {video_path}\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.track(frame, persist=True)\n",
    "\n",
    "    if results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x1, y1, x2, y2 = box\n",
    "            \n",
    "            # Crop the player's torso for color analysis\n",
    "            torso_height = int((y2 - y1) * 0.5)\n",
    "            player_torso_roi = frame[y1:y1 + torso_height, x1:x2]\n",
    "            \n",
    "            team_name, box_color = get_player_team(player_torso_roi)\n",
    "            \n",
    "            # Draw the bounding box with the team's color\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "\n",
    "            # Create the label text with Team and Player ID\n",
    "            label = f\"{team_name} ID: {track_id}\"\n",
    "            \n",
    "            # Position the label text\n",
    "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), (x1 + label_size[0], y1), box_color, cv2.FILLED)\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Player Tracking and Team Segregation', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a26acc",
   "metadata": {},
   "source": [
    "Test 5 using Deepsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4baa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# --- COLOR/TEAM DEFINITIONS ---\n",
    "LOWER_RED_1 = np.array([0, 120, 70])\n",
    "UPPER_RED_1 = np.array([10, 255, 255])\n",
    "LOWER_RED_2 = np.array([170, 120, 70])\n",
    "UPPER_RED_2 = np.array([180, 255, 255])\n",
    "LOWER_SKY_BLUE = np.array([90, 70, 50])\n",
    "UPPER_SKY_BLUE = np.array([120, 255, 255])\n",
    "\n",
    "RED_COLOR_BGR = (0, 0, 255)\n",
    "SKY_BLUE_COLOR_BGR = (235, 206, 135)\n",
    "GREEN_COLOR_BGR = (0, 255, 0)\n",
    "\n",
    "\n",
    "def get_player_team(player_roi):\n",
    "    if player_roi.size == 0:\n",
    "        return \"Undetermined\", GREEN_COLOR_BGR\n",
    "\n",
    "    hsv_roi = cv2.cvtColor(player_roi, cv2.COLOR_BGR2HSV)\n",
    "    red_mask1 = cv2.inRange(hsv_roi, LOWER_RED_1, UPPER_RED_1)\n",
    "    red_mask2 = cv2.inRange(hsv_roi, LOWER_RED_2, UPPER_RED_2)\n",
    "    red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "    sky_blue_mask = cv2.inRange(hsv_roi, LOWER_SKY_BLUE, UPPER_SKY_BLUE)\n",
    "\n",
    "    red_pixel_count = cv2.countNonZero(red_mask)\n",
    "    sky_blue_pixel_count = cv2.countNonZero(sky_blue_mask)\n",
    "\n",
    "    if red_pixel_count > sky_blue_pixel_count and red_pixel_count > 10:\n",
    "        return \"Red Team\", RED_COLOR_BGR\n",
    "    elif sky_blue_pixel_count > red_pixel_count and sky_blue_pixel_count > 10:\n",
    "        return \"Blue Team\", SKY_BLUE_COLOR_BGR\n",
    "    else:\n",
    "        return \"Undetermined\", GREEN_COLOR_BGR\n",
    "\n",
    "\n",
    "# --- MAIN SCRIPT ---\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "tracker = DeepSort(max_age=30, n_init=2, nms_max_overlap=1.0)\n",
    "\n",
    "cap = cv2.VideoCapture('15sec_input_720p.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        confs = r.boxes.conf.cpu().numpy()\n",
    "        clss = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "        for box, conf, cls in zip(boxes, confs, clss):\n",
    "            if int(cls) == 1 and conf > 0.5:  # Assuming class 1 is player\n",
    "                x1, y1, x2, y2 = box.astype(int)\n",
    "                detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'player'))\n",
    "\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        x1, y1, x2, y2 = map(int, ltrb)\n",
    "\n",
    "        torso_height = int((y2 - y1) * 0.5)\n",
    "        player_torso_roi = frame[y1:y1 + torso_height, x1:x2]\n",
    "\n",
    "        team_name, box_color = get_player_team(player_torso_roi)\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "        label = f\"{team_name} ID: {track_id}\"\n",
    "        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "        cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), (x1 + label_size[0], y1), box_color, cv2.FILLED)\n",
    "        cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Player Tracking with DeepSORT & Team Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750aa10",
   "metadata": {},
   "source": [
    "TEST 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfd50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- COLOR/TEAM DEFINITIONS (Same as before) ---\n",
    "LOWER_RED_1 = np.array([0, 120, 70])\n",
    "UPPER_RED_1 = np.array([10, 255, 255])\n",
    "LOWER_RED_2 = np.array([170, 120, 70])\n",
    "UPPER_RED_2 = np.array([180, 255, 255])\n",
    "LOWER_SKY_BLUE = np.array([90, 70, 50])\n",
    "UPPER_SKY_BLUE = np.array([120, 255, 255])\n",
    "RED_COLOR_BGR = (0, 0, 255)\n",
    "SKY_BLUE_COLOR_BGR = (235, 206, 135)\n",
    "GREEN_COLOR_BGR = (0, 255, 0)\n",
    "\n",
    "# --- NEW: APPEARANCE FEATURE FUNCTION ---\n",
    "def create_color_histogram(roi):\n",
    "    \"\"\"Creates a 3D color histogram from the player's torso ROI.\"\"\"\n",
    "    if roi.size == 0:\n",
    "        return None\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    # Use 3 channels (H, S, V), with more bins for Hue for better color distinction\n",
    "    hist = cv2.calcHist([hsv_roi], [0, 1, 2], None, [8, 3, 3], [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
    "    return hist\n",
    "\n",
    "def get_player_team(player_roi):\n",
    "    # This function remains the same as before\n",
    "    if player_roi.size == 0: return \"Undetermined\", GREEN_COLOR_BGR\n",
    "    hsv_roi = cv2.cvtColor(player_roi, cv2.COLOR_BGR2HSV)\n",
    "    red_mask1 = cv2.inRange(hsv_roi, LOWER_RED_1, UPPER_RED_1)\n",
    "    red_mask2 = cv2.inRange(hsv_roi, LOWER_RED_2, UPPER_RED_2)\n",
    "    red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "    sky_blue_mask = cv2.inRange(hsv_roi, LOWER_SKY_BLUE, UPPER_SKY_BLUE)\n",
    "    red_pixel_count = cv2.countNonZero(red_mask)\n",
    "    sky_blue_pixel_count = cv2.countNonZero(sky_blue_mask)\n",
    "    if red_pixel_count > sky_blue_pixel_count and red_pixel_count > 10:\n",
    "        return \"Red Team\", RED_COLOR_BGR\n",
    "    elif sky_blue_pixel_count > red_pixel_count and sky_blue_pixel_count > 10:\n",
    "        return \"Sky Blue Team\", SKY_BLUE_COLOR_BGR\n",
    "    else:\n",
    "        return \"Undetermined\", GREEN_COLOR_BGR\n",
    "\n",
    "# --- MAIN SCRIPT ---\n",
    "model = YOLO('best.pt')\n",
    "video_path = '15sec_input_720p.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# --- NEW: TRACK MANAGEMENT DICTIONARIES ---\n",
    "# active_tracks stores current data for visible players\n",
    "# { track_id: {\"box\": [...], \"team\": \"...\", \"hist\": ..., \"frames_since_seen\": 0} }\n",
    "active_tracks = {}\n",
    "# disappeared_tracks stores data for players who have left the frame\n",
    "# { track_id: {\"box\": [...], \"team\": \"...\", \"hist\": ..., \"frames_since_seen\": 0} }\n",
    "disappeared_tracks = {}\n",
    "\n",
    "# Re-ID parameters\n",
    "MAX_FRAMES_TO_DISAPPEAR = 30  # How many frames to keep a disappeared track in memory\n",
    "HIST_COMPARISON_THRESHOLD = 0.6  # How similar histograms must be to be a match\n",
    "\n",
    "frame_num = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_num += 1\n",
    "\n",
    "    results = model.track(frame, persist=True)\n",
    "    \n",
    "    current_track_ids = set()\n",
    "    if results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "        # --- PROCESS CURRENTLY VISIBLE TRACKS ---\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            current_track_ids.add(track_id)\n",
    "            \n",
    "            # Crop player's torso for analysis\n",
    "            x1, y1, x2, y2 = box\n",
    "            torso_height = int((y2 - y1) * 0.5)\n",
    "            player_torso_roi = frame[y1:y1 + torso_height, x1:x2]\n",
    "\n",
    "            # --- RE-IDENTIFICATION LOGIC ---\n",
    "            if track_id not in active_tracks:\n",
    "                # This is a NEW track ID. Check if it matches a disappeared player.\n",
    "                is_new_player = True\n",
    "                new_hist = create_color_histogram(player_torso_roi)\n",
    "                if new_hist is not None:\n",
    "                    best_match_id = -1\n",
    "                    max_similarity = -1\n",
    "                    \n",
    "                    # Compare with all disappeared tracks\n",
    "                    for d_id, d_data in list(disappeared_tracks.items()):\n",
    "                        similarity = cv2.compareHist(new_hist, d_data[\"hist\"], cv2.HISTCMP_CORREL)\n",
    "                        if similarity > HIST_COMPARISON_THRESHOLD and similarity > max_similarity:\n",
    "                            max_similarity = similarity\n",
    "                            best_match_id = d_id\n",
    "                    \n",
    "                    if best_match_id != -1:\n",
    "                        # Match found! Re-assign the old ID.\n",
    "                        print(f\"Re-identified: New ID {track_id} -> Old ID {best_match_id}\")\n",
    "                        active_tracks[best_match_id] = disappeared_tracks[best_match_id]\n",
    "                        active_tracks[best_match_id][\"box\"] = box # Update box\n",
    "                        active_tracks[best_match_id][\"frames_since_seen\"] = 0 # Reset counter\n",
    "                        del disappeared_tracks[best_match_id] # Remove from disappeared\n",
    "                        current_track_ids.add(best_match_id) # Add to current set\n",
    "                        is_new_player = False\n",
    "\n",
    "                if is_new_player:\n",
    "                    # No match found, it's a genuinely new player.\n",
    "                    team_name, _ = get_player_team(player_torso_roi)\n",
    "                    active_tracks[track_id] = {\n",
    "                        \"box\": box,\n",
    "                        \"team\": team_name,\n",
    "                        \"hist\": new_hist,\n",
    "                        \"frames_since_seen\": 0\n",
    "                    }\n",
    "            else:\n",
    "                # This is an existing, tracked player. Update their data.\n",
    "                active_tracks[track_id][\"box\"] = box\n",
    "                active_tracks[track_id][\"frames_since_seen\"] = 0\n",
    "\n",
    "    # --- MANAGE DISAPPEARED TRACKS ---\n",
    "    # Increment 'frames_since_seen' for all active tracks not seen in this frame\n",
    "    disappeared_ids = set(active_tracks.keys()) - current_track_ids\n",
    "    for track_id in disappeared_ids:\n",
    "        active_tracks[track_id][\"frames_since_seen\"] += 1\n",
    "        # If a player has been gone for too long, move them to disappeared_tracks\n",
    "        if active_tracks[track_id][\"frames_since_seen\"] > 5: # Small buffer before moving\n",
    "            disappeared_tracks[track_id] = active_tracks.pop(track_id)\n",
    "            print(f\"Track {track_id} moved to disappeared.\")\n",
    "\n",
    "    # Remove tracks that have been disappeared for too long\n",
    "    for track_id in list(disappeared_tracks.keys()):\n",
    "        if disappeared_tracks[track_id][\"frames_since_seen\"] > MAX_FRAMES_TO_DISAPPEAR:\n",
    "            print(f\"Track {track_id} removed permanently from memory.\")\n",
    "            del disappeared_tracks[track_id]\n",
    "\n",
    "    # --- VISUALIZATION ---\n",
    "    for track_id, data in active_tracks.items():\n",
    "        if data[\"frames_since_seen\"] == 0: # Only draw active players\n",
    "            box = data['box']\n",
    "            team_name, box_color = get_player_team(frame[box[1]:box[3], box[0]:box[2]])\n",
    "            label = f\"{team_name} ID: {track_id}\"\n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), box_color, 2)\n",
    "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(frame, (box[0], box[1] - label_size[1] - 10), (box[0] + label_size[0], box[1]), box_color, cv2.FILLED)\n",
    "            cv2.putText(frame, label, (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "    cv2.imshow('Player Re-Identification', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
